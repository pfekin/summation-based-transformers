{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install darts"
      ],
      "metadata": {
        "id": "y1NvWI0gtj_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "xR3f0TCsjTP2",
        "outputId": "6466c710-1e7b-485c-d8d9-3d8bb8ae80b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "======================================================================\n",
            "Dataset: ETTh1\n",
            "======================================================================\n",
            "Baseline params: 1,181,920\n",
            "Hybrid params: 1,082,592\n",
            "\n",
            "Training baseline PatchTST...\n",
            "Epoch 5: Train Loss=0.3140 | Val Loss=0.3856 | Best=0.3369\n",
            "Epoch 10: Train Loss=0.2826 | Val Loss=0.4056 | Best=0.3369\n",
            "\n",
            "Training hybrid PatchTST (summation)...\n",
            "Epoch 5: Train Loss=0.3382 | Val Loss=0.3277 | Best=0.3274\n",
            "Epoch 10: Train Loss=0.2997 | Val Loss=0.3266 | Best=0.3266\n",
            "\n",
            "Validation Results:\n",
            "Baseline best val MSE: 0.3369 (time 124.8s)\n",
            "Hybrid   best val MSE: 0.3266 (time 78.7s)\n",
            "\n",
            "Test Results:\n",
            "Baseline -> MSE: 0.4451, MAE: 0.4708, Inference: 3020.7 samples/s\n",
            "Hybrid   -> MSE: 0.4301, MAE: 0.4571, Inference: 4199.7 samples/s\n",
            "\n",
            "======================================================================\n",
            "Dataset: ETTh2\n",
            "======================================================================\n",
            "Baseline params: 1,181,920\n",
            "Hybrid params: 1,082,592\n",
            "\n",
            "Training baseline PatchTST...\n",
            "Epoch 5: Train Loss=0.3020 | Val Loss=0.3346 | Best=0.2804\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1328419534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         )\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1328419534.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(dataset_name, train_loader, val_loader, test_loader, n_vars, config, device)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining baseline PatchTST...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     baseline_val = train_model(baseline_model, train_loader, val_loader,\n\u001b[0m\u001b[1;32m    484\u001b[0m                                criterion, optimizer_baseline, device, config['n_epochs'])\n\u001b[1;32m    485\u001b[0m     \u001b[0mbaseline_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1328419534.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, n_epochs)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;31m# Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     def backward(\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     ):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Minimal PatchTST Implementation with Summation-Based Attention\n",
        "\n",
        "Compares:\n",
        "1. Baseline PatchTST with standard attention\n",
        "2. Hybrid PatchTST with summation attention (trained from scratch)\n",
        "\n",
        "Benchmark on ETTh1, ETTh2, ETTm1, ETTm2, Weather,  Traffic datasets\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Darts datasets for Traffic / Weather\n",
        "from darts.datasets import TrafficDataset, WeatherDataset\n",
        "\n",
        "# Data loading\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, data, seq_len, pred_len):\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx : idx + self.seq_len]\n",
        "        y = self.data[idx + self.seq_len : idx + self.seq_len + self.pred_len]\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def timeseries_to_dataframe(ts):\n",
        "    \"\"\"Convert Darts TimeSeries to pandas DataFrame, handling 3D arrays\"\"\"\n",
        "    # Newer Darts versions (>=0.30.0)\n",
        "    if hasattr(ts, \"pd_dataframe\"):\n",
        "        df = ts.pd_dataframe()\n",
        "        # Handle potential 3D structure\n",
        "        if isinstance(df, pd.DataFrame):\n",
        "            return df\n",
        "        else:\n",
        "            arr = ts.all_values(copy=False)\n",
        "            if arr.ndim == 3:\n",
        "                arr = arr.squeeze(-1)  # Remove trailing dimension (T, n_vars, 1) -> (T, n_vars)\n",
        "            cols = [f\"var_{i}\" for i in range(arr.shape[1])]\n",
        "            return pd.DataFrame(arr, columns=cols)\n",
        "    # Older versions\n",
        "    elif hasattr(ts, \"all_values\"):\n",
        "        arr = ts.all_values(copy=False)\n",
        "        if arr.ndim == 3:\n",
        "            arr = arr.squeeze(-1)  # Convert (T, n_vars, 1) -> (T, n_vars)\n",
        "        cols = [f\"var_{i}\" for i in range(arr.shape[1])]\n",
        "        return pd.DataFrame(arr, columns=cols)\n",
        "    else:\n",
        "        raise AttributeError(\"Unsupported Darts TimeSeries object. Please update Darts.\")\n",
        "\n",
        "\n",
        "def load_dataset_general(name, seq_len, pred_len, batch_size=32,\n",
        "                         val_ratio=0.2, test_ratio=0.2, max_vars=None):\n",
        "    \"\"\"\n",
        "    Generalized loader:\n",
        "      - ETTh1, ETTh2, ETTm1, ETTm2: raw CSV from Zhou repo\n",
        "      - Traffic / Weather: from Darts loaders\n",
        "    \"\"\"\n",
        "    if name == \"ETTh1\":\n",
        "        url = \"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv\"\n",
        "        df = pd.read_csv(url)\n",
        "        if \"date\" in df.columns:\n",
        "            df = df.drop(columns=[\"date\"])\n",
        "    elif name == \"ETTh2\":\n",
        "        url = \"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh2.csv\"\n",
        "        df = pd.read_csv(url)\n",
        "        if \"date\" in df.columns:\n",
        "            df = df.drop(columns=[\"date\"])\n",
        "    elif name == \"ETTm1\":\n",
        "        url = \"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTm1.csv\"\n",
        "        df = pd.read_csv(url)\n",
        "        if \"date\" in df.columns:\n",
        "            df = df.drop(columns=[\"date\"])\n",
        "    elif name == \"ETTm2\":\n",
        "        url = \"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTm2.csv\"\n",
        "        df = pd.read_csv(url)\n",
        "        if \"date\" in df.columns:\n",
        "            df = df.drop(columns=[\"date\"])\n",
        "    elif name == \"Traffic\":\n",
        "        ts = TrafficDataset().load()\n",
        "        df = timeseries_to_dataframe(ts)\n",
        "    elif name == \"Weather\":\n",
        "        ts = WeatherDataset().load()\n",
        "        df = timeseries_to_dataframe(ts)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown dataset: {name}\")\n",
        "\n",
        "    if max_vars is not None and df.shape[1] > max_vars:\n",
        "        df = df.iloc[:, :max_vars]\n",
        "\n",
        "    values = df.values\n",
        "    T, n_vars = values.shape\n",
        "\n",
        "    # Train/val/test split\n",
        "    n_test = int(T * test_ratio)\n",
        "    n_val = int(T * val_ratio)\n",
        "    n_train = T - n_val - n_test\n",
        "\n",
        "    train_vals = values[:n_train]\n",
        "    val_vals = values[n_train:n_train+n_val]\n",
        "    test_vals = values[n_train+n_val:]\n",
        "\n",
        "    # Standardize\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(train_vals)\n",
        "    train_scaled = scaler.transform(train_vals)\n",
        "    val_scaled = scaler.transform(val_vals)\n",
        "    test_scaled = scaler.transform(test_vals)\n",
        "\n",
        "    # Handle NaN/Inf values after standardization\n",
        "    train_scaled = np.nan_to_num(train_scaled, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    val_scaled = np.nan_to_num(val_scaled, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    test_scaled = np.nan_to_num(test_scaled, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    # Wrap in PyTorch datasets\n",
        "    train_ds = TimeSeriesDataset(train_scaled, seq_len, pred_len)\n",
        "    val_ds = TimeSeriesDataset(val_scaled, seq_len, pred_len)\n",
        "    test_ds = TimeSeriesDataset(test_scaled, seq_len, pred_len)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader, n_vars, scaler\n",
        "\n",
        "\n",
        "# Patching layer\n",
        "\n",
        "class Patching(nn.Module):\n",
        "    \"\"\"Convert time series into patches\"\"\"\n",
        "    def __init__(self, patch_len, stride):\n",
        "        super().__init__()\n",
        "        self.patch_len = patch_len\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, seq_len, channels)\n",
        "        batch_size, seq_len, n_vars = x.shape\n",
        "\n",
        "        # Calculate number of patches\n",
        "        num_patches = (seq_len - self.patch_len) // self.stride + 1\n",
        "\n",
        "        # Extract patches\n",
        "        patches = torch.zeros(batch_size, n_vars, num_patches, self.patch_len, device=x.device)\n",
        "        for i in range(num_patches):\n",
        "            start = i * self.stride\n",
        "            end = start + self.patch_len\n",
        "            patches[:, :, i, :] = x[:, start:end, :].transpose(1, 2)\n",
        "\n",
        "        # Reshape: (batch, n_vars, num_patches, patch_len) -> (batch*n_vars, num_patches, patch_len)\n",
        "        patches = patches.reshape(batch_size * n_vars, num_patches, self.patch_len)\n",
        "\n",
        "        return patches, n_vars, num_patches\n",
        "\n",
        "\n",
        "# Attention blocks\n",
        "\n",
        "class StandardAttentionBlock(nn.Module):\n",
        "    \"\"\"Standard transformer block with multi-head self-attention\"\"\"\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Self-attention\n",
        "        attn_out, _ = self.attention(x, x, x)\n",
        "        x = self.norm1(x + attn_out)\n",
        "\n",
        "        # Feed-forward\n",
        "        ffn_out = self.ffn(x)\n",
        "        x = self.norm2(x + ffn_out)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class SummationAttentionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Summation-based attention block\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model, bias=False),\n",
        "            nn.GELU(),\n",
        "            #nn.Linear(d_model, d_model, bias=False),\n",
        "            #nn.GELU(),\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        summed = self.proj(x)\n",
        "        x = self.norm1(x + summed)\n",
        "\n",
        "        ffn_out = self.ffn(x)\n",
        "        x = self.norm2(x + ffn_out)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# PatchTST Models\n",
        "\n",
        "class BaselinePatchTST(nn.Module):\n",
        "    \"\"\"PatchTST with standard attention\"\"\"\n",
        "    def __init__(self, n_vars, seq_len, pred_len, patch_len=16, stride=8,\n",
        "                 d_model=128, n_heads=8, n_layers=3, d_ff=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patching = Patching(patch_len, stride)\n",
        "\n",
        "        # Patch embedding\n",
        "        self.patch_embedding = nn.Linear(patch_len, d_model)\n",
        "\n",
        "        # Positional encoding\n",
        "        num_patches = (seq_len - patch_len) // stride + 1\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1, num_patches, d_model))\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            StandardAttentionBlock(d_model, n_heads, d_ff, dropout)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "\n",
        "        # Prediction head\n",
        "        self.head = nn.Linear(d_model * num_patches, pred_len)\n",
        "\n",
        "        self.n_vars = n_vars\n",
        "        self.pred_len = pred_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, seq_len, n_vars)\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Patching: (batch*n_vars, num_patches, patch_len)\n",
        "        patches, n_vars, num_patches = self.patching(x)\n",
        "\n",
        "        # Embed patches\n",
        "        x = self.patch_embedding(patches)  # (batch*n_vars, num_patches, d_model)\n",
        "\n",
        "        # Add positional encoding\n",
        "        x = x + self.pos_encoding\n",
        "\n",
        "        # Transformer blocks\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Flatten and predict\n",
        "        x = x.reshape(batch_size * n_vars, -1)  # (batch*n_vars, num_patches * d_model)\n",
        "        x = self.head(x)  # (batch*n_vars, pred_len)\n",
        "\n",
        "        # Reshape to (batch, pred_len, n_vars)\n",
        "        x = x.reshape(batch_size, n_vars, self.pred_len).transpose(1, 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class HybridPatchTST(nn.Module):\n",
        "    \"\"\"PatchTST with summation attention + final standard attention\"\"\"\n",
        "    def __init__(self, n_vars, seq_len, pred_len, patch_len=16, stride=8,\n",
        "                 d_model=128, n_heads=8, n_layers=3, d_ff=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patching = Patching(patch_len, stride)\n",
        "\n",
        "        # Patch embedding\n",
        "        self.patch_embedding = nn.Linear(patch_len, d_model)\n",
        "\n",
        "        # Positional encoding\n",
        "        num_patches = (seq_len - patch_len) // stride + 1\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1, num_patches, d_model))\n",
        "\n",
        "        # Hybrid blocks: summation + final attention\n",
        "        self.summation_blocks = nn.ModuleList([\n",
        "            SummationAttentionBlock(d_model, d_ff, dropout)\n",
        "            for _ in range(n_layers - 1)\n",
        "        ])\n",
        "        self.final_attention = StandardAttentionBlock(d_model, n_heads, d_ff, dropout)\n",
        "\n",
        "        # Prediction head\n",
        "        self.head = nn.Linear(d_model * num_patches, pred_len)\n",
        "\n",
        "        self.n_vars = n_vars\n",
        "        self.pred_len = pred_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, seq_len, n_vars)\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Patching\n",
        "        patches, n_vars, num_patches = self.patching(x)\n",
        "\n",
        "        # Embed patches\n",
        "        x = self.patch_embedding(patches)\n",
        "\n",
        "        # Positional encoding using multiplication\n",
        "        x = x * self.pos_encoding\n",
        "        #x = x + self.pos_encoding\n",
        "\n",
        "        # Summation blocks\n",
        "        for block in self.summation_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Final attention\n",
        "        x = self.final_attention(x)\n",
        "\n",
        "        # Flatten and predict\n",
        "        x = x.reshape(batch_size * n_vars, -1)\n",
        "        x = self.head(x)\n",
        "\n",
        "        # Reshape to (batch, pred_len, n_vars)\n",
        "        x = x.reshape(batch_size, n_vars, self.pred_len).transpose(1, 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Training & evaluation\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, n_epochs=30):\n",
        "    \"\"\"Train model and return best validation loss\"\"\"\n",
        "    best_val_loss = float(\"inf\")\n",
        "\n",
        "    # Add gradient clipping to prevent explosions\n",
        "    max_grad_norm = 1.0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for past_values, future_values in train_loader:\n",
        "            past_values = past_values.to(device)\n",
        "            future_values = future_values.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(past_values)\n",
        "            loss = criterion(outputs, future_values)\n",
        "\n",
        "            # Check for NaN\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"  WARNING: NaN loss detected at epoch {epoch+1}, skipping batch\")\n",
        "                continue\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for past_values, future_values in val_loader:\n",
        "                past_values = past_values.to(device)\n",
        "                future_values = future_values.to(device)\n",
        "\n",
        "                outputs = model(past_values)\n",
        "                loss = criterion(outputs, future_values)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        best_val_loss = min(best_val_loss, val_loss)\n",
        "\n",
        "        # Early stopping if training diverges\n",
        "        if torch.isnan(torch.tensor(train_loss)) or torch.isnan(torch.tensor(val_loss)):\n",
        "            print(f\"  Training diverged at epoch {epoch+1}. Stopping early.\")\n",
        "            break\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} | Val Loss={val_loss:.4f} | Best={best_val_loss:.4f}\")\n",
        "\n",
        "    return best_val_loss\n",
        "\n",
        "\n",
        "def evaluate_model(model, loader, device):\n",
        "    \"\"\"Compute MSE and MAE on a given DataLoader.\"\"\"\n",
        "    model.eval()\n",
        "    mse_loss = 0.0\n",
        "    mae_loss = 0.0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y_pred = model(x)\n",
        "            mse_loss += torch.nn.functional.mse_loss(y_pred, y, reduction=\"sum\").item()\n",
        "            mae_loss += torch.nn.functional.l1_loss(y_pred, y, reduction=\"sum\").item()\n",
        "            count += y.numel()\n",
        "    return mse_loss / count, mae_loss / count\n",
        "\n",
        "\n",
        "def measure_inference_speed(model, loader, device, warmup=2, reps=5):\n",
        "    \"\"\"Measure inference speed in samples/sec.\"\"\"\n",
        "    model.eval()\n",
        "    # Warmup passes\n",
        "    with torch.no_grad():\n",
        "        for i, (x, _) in enumerate(loader):\n",
        "            if i >= warmup:\n",
        "                break\n",
        "            _ = model(x.to(device))\n",
        "\n",
        "    # Timed passes\n",
        "    total_time = 0.0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for r in range(reps):\n",
        "            for x, _ in loader:\n",
        "                x = x.to(device)\n",
        "                batch_size = x.size(0)\n",
        "                start = time.time()\n",
        "                _ = model(x)\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.synchronize()\n",
        "                total_time += time.time() - start\n",
        "                total_samples += batch_size\n",
        "    return total_samples / total_time\n",
        "\n",
        "\n",
        "# Main experiment\n",
        "\n",
        "def run_experiment(dataset_name, train_loader, val_loader, test_loader, n_vars, config, device):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"Dataset: {dataset_name}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Initialize models\n",
        "    baseline_model = BaselinePatchTST(\n",
        "        n_vars=n_vars, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
        "        patch_len=config['patch_len'], stride=config['stride'],\n",
        "        d_model=config['d_model'], n_heads=config['n_heads'],\n",
        "        n_layers=config['n_layers'], d_ff=config['d_ff'], dropout=config['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "    hybrid_model = HybridPatchTST(\n",
        "        n_vars=n_vars, seq_len=config['seq_len'], pred_len=config['pred_len'],\n",
        "        patch_len=config['patch_len'], stride=config['stride'],\n",
        "        d_model=config['d_model'], n_heads=config['n_heads'],\n",
        "        n_layers=config['n_layers'], d_ff=config['d_ff'], dropout=config['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "    print(f\"Baseline params: {sum(p.numel() for p in baseline_model.parameters()):,}\")\n",
        "    print(f\"Hybrid params: {sum(p.numel() for p in hybrid_model.parameters()):,}\")\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer_baseline = torch.optim.Adam(baseline_model.parameters(), lr=config['lr'])\n",
        "    optimizer_hybrid = torch.optim.Adam(hybrid_model.parameters(), lr=config['lr'])\n",
        "\n",
        "    # Train baseline\n",
        "    print(\"\\nTraining baseline PatchTST...\")\n",
        "    start_time = time.time()\n",
        "    baseline_val = train_model(baseline_model, train_loader, val_loader,\n",
        "                               criterion, optimizer_baseline, device, config['n_epochs'])\n",
        "    baseline_time = time.time() - start_time\n",
        "\n",
        "    # Train hybrid\n",
        "    print(\"\\nTraining hybrid PatchTST (summation)...\")\n",
        "    start_time = time.time()\n",
        "    hybrid_val = train_model(hybrid_model, train_loader, val_loader,\n",
        "                             criterion, optimizer_hybrid, device, config['n_epochs'])\n",
        "    hybrid_time = time.time() - start_time\n",
        "\n",
        "    print(\"\\nValidation Results:\")\n",
        "    print(f\"Baseline best val MSE: {baseline_val:.4f} (time {baseline_time:.1f}s)\")\n",
        "    print(f\"Hybrid   best val MSE: {hybrid_val:.4f} (time {hybrid_time:.1f}s)\")\n",
        "\n",
        "    # Final test evaluation\n",
        "    baseline_test_mse, baseline_test_mae = evaluate_model(baseline_model, test_loader, device)\n",
        "    hybrid_test_mse, hybrid_test_mae   = evaluate_model(hybrid_model, test_loader, device)\n",
        "\n",
        "    baseline_speed = measure_inference_speed(baseline_model, test_loader, device)\n",
        "    hybrid_speed   = measure_inference_speed(hybrid_model, test_loader, device)\n",
        "\n",
        "    print(\"\\nTest Results:\")\n",
        "    print(f\"Baseline -> MSE: {baseline_test_mse:.4f}, MAE: {baseline_test_mae:.4f}, Inference: {baseline_speed:.1f} samples/s\")\n",
        "    print(f\"Hybrid   -> MSE: {hybrid_test_mse:.4f}, MAE: {hybrid_test_mae:.4f}, Inference: {hybrid_speed:.1f} samples/s\")\n",
        "\n",
        "    return {\n",
        "        'dataset': dataset_name,\n",
        "        'baseline_mse': baseline_test_mse,\n",
        "        'baseline_mae': baseline_test_mae,\n",
        "        'hybrid_mse': hybrid_test_mse,\n",
        "        'hybrid_mae': hybrid_test_mae,\n",
        "        'baseline_speed': baseline_speed,\n",
        "        'hybrid_speed': hybrid_speed\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    CONFIG = {\n",
        "        'seq_len': 512,\n",
        "        'pred_len': 96,\n",
        "        'patch_len': 16,\n",
        "        'stride': 8,\n",
        "        'd_model': 128,\n",
        "        'n_heads': 8,\n",
        "        'n_layers': 3,\n",
        "        'd_ff': 256,\n",
        "        'batch_size': 32,\n",
        "        'n_epochs': 10,\n",
        "        'lr': 1e-4,\n",
        "        'dropout': 0.15\n",
        "    }\n",
        "\n",
        "    datasets_to_run = [\"ETTh1\", \"ETTh2\", \"ETTm1\", \"ETTm2\", \"Weather\", \"Traffic\"]\n",
        "\n",
        "    results = []\n",
        "    for dset in datasets_to_run:\n",
        "        max_vars = 100 if dset == \"Traffic\" else None # WARNING, it uses > 8Gb of VRAM\n",
        "        train_loader, val_loader, test_loader, n_vars, _ = load_dataset_general(\n",
        "            dset, CONFIG['seq_len'], CONFIG['pred_len'],\n",
        "            batch_size=CONFIG['batch_size'], max_vars=max_vars\n",
        "        )\n",
        "        result = run_experiment(dset, train_loader, val_loader, test_loader, n_vars, CONFIG, device)\n",
        "        results.append(result)\n",
        "\n",
        "    # Print summary table\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Final benchmark summary\")\n",
        "    print(\"=\"*70)\n",
        "    for r in results:\n",
        "        print(f\"\\n{r['dataset']}:\")\n",
        "        print(f\"  Baseline: MSE={r['baseline_mse']:.4f}, MAE={r['baseline_mae']:.4f}, Speed={r['baseline_speed']:.1f} samples/s\")\n",
        "        print(f\"  Hybrid:   MSE={r['hybrid_mse']:.4f}, MAE={r['hybrid_mae']:.4f}, Speed={r['hybrid_speed']:.1f} samples/s\")\n",
        "        improvement = ((r['baseline_mse'] - r['hybrid_mse']) / r['baseline_mse']) * 100\n",
        "        speedup = r['hybrid_speed'] / r['baseline_speed']\n",
        "        print(f\"  -> MSE improvement: {improvement:+.1f}%, Speed ratio: {speedup:.2f}x\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nouvelle section"
      ],
      "metadata": {
        "id": "OTgiuQnTm0go"
      }
    }
  ]
}